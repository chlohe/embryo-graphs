{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloe/.conda/envs/pyg/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from torchvision import ops\n",
    "from sklearn import metrics\n",
    "\n",
    "from models import maskrcnn2d\n",
    "from datasets import T4SegmentationDataset2DDepthAsClass\n",
    "from predict_frame import simple_nms, spicy_nms, global_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crowd_nms(image_tensor, masks, boxes, scores, depths, conf_threshold=0.6, iou_threshold=0.9):\n",
    "    scores = scores.cpu().detach()\n",
    "    boxes = boxes.cpu().detach()\n",
    "    boxes_orig = torch.clone(boxes)\n",
    "    boxes_orig = np.array(boxes_orig).tolist()\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    box_keep = []\n",
    "    scores_keep = []\n",
    "    keep = [0 for i in range(len(boxes))]\n",
    "\n",
    "    while len(scores) > 0:\n",
    "        filter1 = np.where(scores > 0.2)[0]\n",
    "        boxes = boxes[filter1]\n",
    "        scores = scores[filter1]\n",
    "        if len(scores) < 1:\n",
    "            break\n",
    "        order = np.argsort(-scores)\n",
    "        i = np.argwhere(order == 0)[0][0]\n",
    "        a1 = boxes[i]\n",
    "        a2 = scores[i]\n",
    "        s = (a1[3] - a1[1]) * (a1[2] - a1[0])\n",
    "        boxes = np.delete(boxes, i, axis=0)\n",
    "        scores = np.delete(scores, i, axis=0)\n",
    "        box_keep.append(a1)\n",
    "        scores_keep.append(a2)\n",
    "\n",
    "        if len(order) == 1:\n",
    "            break\n",
    "        for i in range(len(boxes)):\n",
    "            xx1 = boxes[i][0]\n",
    "            yy1 = boxes[i][1]\n",
    "            xx2 = boxes[i][2]\n",
    "            yy2 = boxes[i][3]\n",
    "            x1 = max(a1[0], xx1)\n",
    "            y1 = max(a1[1], yy1)\n",
    "            x2 = min(a1[2], xx2)\n",
    "            y2 = min(a1[3], yy2)\n",
    "            inter = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "            area = (yy2 - yy1) * (xx2 - xx1)\n",
    "            union = s + area - inter\n",
    "            iou = inter / (union + 1e-6)\n",
    "            ar = np.minimum(s, area) / np.maximum(s, area)\n",
    "            if iou < iou_threshold:\n",
    "                continue\n",
    "            scores[i] *= 1 / np.pi * np.exp(-0.5 * (iou ** 2 + ar ** 2))\n",
    "    if len(box_keep) > 1:\n",
    "        box_keep = np.array(box_keep).tolist()\n",
    "    box_keep = [box.numpy().tolist() for box in box_keep]\n",
    "    for box in box_keep:\n",
    "        keep[boxes_orig.index(box)] = 1\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(pred, target):\n",
    "    # Binarise vectors and put into contigious memory\n",
    "    pred = ((pred > 0.5).float() * 1).squeeze().contiguous()\n",
    "    target = ((target > 0.5).float() * 1).squeeze().contiguous()\n",
    "\n",
    "\n",
    "    intersection = (pred * target).sum().sum()\n",
    "    union = (pred + target).sum().sum()\n",
    "\n",
    "    return ((2. * intersection) / union).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_and_dice(boxes, masks, depths, gt_boxes, gt_masks, gt_depths, iou_threshold=0.7):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    matched_boxes = []\n",
    "    dice_scores = []\n",
    "    for gt_box, gt_mask, gt_depth in zip(gt_boxes, gt_masks, gt_depths):\n",
    "        delta_depths = [abs(depth.item() - gt_depth.item()) for depth in depths]\n",
    "        # Find all detections within 1 FP\n",
    "        detections_at_similar_depth = [(box, mask) for box, mask, delta in zip(boxes, masks, delta_depths) if delta <= 1 and box.numpy().tolist() not in matched_boxes]\n",
    "        if len(detections_at_similar_depth) == 0:\n",
    "            # No detections on same plane\n",
    "            fn += 1\n",
    "        else:\n",
    "            boxes_at_similar_depth = torch.cat([box.unsqueeze(0) for box, _ in detections_at_similar_depth])\n",
    "            masks_at_similar_depth = torch.cat([mask.unsqueeze(0) for _, mask in detections_at_similar_depth])\n",
    "            # Compute IOUs\n",
    "            ious = ops.box_iou(boxes_at_similar_depth, gt_box.unsqueeze(0))\n",
    "            if ious.squeeze().max() < iou_threshold:\n",
    "                # No sufficiently overlapping detections\n",
    "                fn += 1\n",
    "            else:\n",
    "                max_iou_idx = np.argmax(ious.squeeze())\n",
    "                matched_boxes.append(boxes_at_similar_depth[max_iou_idx].numpy().tolist())\n",
    "                tp += 1\n",
    "                # Compute dice score\n",
    "                dice = dice_score(gt_mask.cuda(), masks_at_similar_depth[max_iou_idx].cuda())\n",
    "                dice_scores.append(dice.cpu().item())\n",
    "    fp = len(boxes) - len(matched_boxes)\n",
    "    return tp, fp, fn, dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_seg(fold, iou_threshold=0.7, conf_threshold=0.7, nms=spicy_nms):\n",
    "    # Setup\n",
    "    dataset = T4SegmentationDataset2DDepthAsClass(\n",
    "        data_dir='/datasets/test/stacks/t4', \n",
    "        label_dir='/datasets/test/seg/t4'\n",
    "    )\n",
    "    print(f'N = {len(dataset)}')\n",
    "    model = maskrcnn2d(\n",
    "        12).cuda() if torch.cuda.is_available() else maskrcnn2d(12)\n",
    "    model.load_state_dict(torch.load(f'../fold_{fold}_model_2000_new_data.ckpt'))\n",
    "    model.eval()\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    dice_scores = []\n",
    "\n",
    "    # Forward through seg model\n",
    "    for img_idx in range(len(dataset)):\n",
    "        image, target = dataset[img_idx]\n",
    "        image_tensor = torch.from_numpy(image).cuda().float().permute(2, 0, 1).unsqueeze(0)\n",
    "        pred = model.forward(image_tensor)\n",
    "        # Extract result\n",
    "        pred = pred[0]\n",
    "        masks = pred['masks']\n",
    "        boxes = pred['boxes'].int()\n",
    "        scores = pred['scores']\n",
    "        depths = pred['labels']\n",
    "        # Do NMS\n",
    "        keep = np.array(nms(None, masks, boxes, scores, depths, conf_threshold=conf_threshold, iou_threshold=iou_threshold))\n",
    "        if len([k for k in keep if k == 1]) == 0:\n",
    "            fn += len(keep)\n",
    "            continue\n",
    "        final_masks = [masks[i] for i, k in enumerate(keep) if k == 1]\n",
    "        final_boxes = torch.cat([boxes[i].unsqueeze(0) for i, k in enumerate(keep) if k == 1], axis=0).int().cpu()\n",
    "        final_depths = [depths[i] for i, k in enumerate(keep) if k == 1]\n",
    "        # Compute metrics\n",
    "        sample_tp, sample_fp, sample_fn, sample_dice_scores = compute_confusion_and_dice(\n",
    "            final_boxes, \n",
    "            final_masks, \n",
    "            final_depths, \n",
    "            target['boxes'].int(),\n",
    "            target['masks'], \n",
    "            target['labels'], \n",
    "            iou_threshold=iou_threshold\n",
    "        )\n",
    "        tp += sample_tp\n",
    "        fp += sample_fp\n",
    "        fn += sample_fn\n",
    "        dice_scores.extend(sample_dice_scores)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    mean_dice, std_dice = np.mean(dice_scores), np.std(dice_scores)\n",
    "    N = tp + fn\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return precision, recall, f1, mean_dice, std_dice, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_with_folds(conf_threshold, iou_threshold, nms):\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    f1s = []\n",
    "    dice_scores = []\n",
    "    for fold in range(5):\n",
    "        print(f'Evaluating fold {fold}')\n",
    "        precision, recall, f1, mean_dice, std_dice, N = eval_seg(fold, conf_threshold=conf_threshold, iou_threshold=iou_threshold, nms=nms)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1s.append(f1)\n",
    "        dice_scores.append(mean_dice)\n",
    "\n",
    "    print(f'Precision {np.mean(precisions)} ({np.std(precisions)}); Recall {np.mean(recalls)} ({np.std(recalls)}); F1 {np.mean(f1s)} ({np.std(f1s)}); Mean Dice {np.mean(dice_scores)} ({np.std(dice_scores)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloe/.local/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 62\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m conf_thresholds:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m iou_thresholds:\n\u001b[0;32m---> 10\u001b[0m         _, _, f1, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43meval_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m f1 \u001b[38;5;241m>\u001b[39m best_f1:\n\u001b[1;32m     12\u001b[0m             best_f1 \u001b[38;5;241m=\u001b[39m f1\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36meval_seg\u001b[0;34m(fold, iou_threshold, conf_threshold, nms)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Forward through seg model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m---> 20\u001b[0m     image, target \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(image)\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(image_tensor)\n",
      "File \u001b[0;32m~/cell-segmentation-3d/notebooks/../datasets/cells2d_depth_as_class.py:26\u001b[0m, in \u001b[0;36mT4SegmentationDataset2DDepthAsClass.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Get example from segmentation dataset\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     item, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m     label \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m: label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: (label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepths\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m11\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mint64),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miscrowd\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m]),))\u001b[38;5;241m.\u001b[39mint()\n\u001b[1;32m     34\u001b[0m     }\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# DIRTY HACK - USE SUPERFOCUS IN THE FUTURE\u001b[39;00m\n",
      "File \u001b[0;32m~/cell-segmentation-3d/notebooks/../datasets/cells2d.py:119\u001b[0m, in \u001b[0;36mT4SegmentationDataset2D.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    116\u001b[0m plane_imgs \u001b[38;5;241m=\u001b[39m [io\u001b[38;5;241m.\u001b[39mimread(plane_path, as_gray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    117\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m _, plane_path \u001b[38;5;129;01min\u001b[39;00m stack\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    118\u001b[0m plane_imgs \u001b[38;5;241m=\u001b[39m [img[\u001b[38;5;241m50\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m plane_imgs]\n\u001b[0;32m--> 119\u001b[0m plane_imgs \u001b[38;5;241m=\u001b[39m [resize(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplane_size) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m plane_imgs]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Mask out the edges\u001b[39;00m\n\u001b[1;32m    121\u001b[0m plane_imgs \u001b[38;5;241m=\u001b[39m [img \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircle_mask \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m plane_imgs]\n",
      "File \u001b[0;32m~/cell-segmentation-3d/notebooks/../datasets/cells2d.py:119\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m plane_imgs \u001b[38;5;241m=\u001b[39m [io\u001b[38;5;241m.\u001b[39mimread(plane_path, as_gray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    117\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m _, plane_path \u001b[38;5;129;01min\u001b[39;00m stack\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    118\u001b[0m plane_imgs \u001b[38;5;241m=\u001b[39m [img[\u001b[38;5;241m50\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m plane_imgs]\n\u001b[0;32m--> 119\u001b[0m plane_imgs \u001b[38;5;241m=\u001b[39m [\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplane_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m plane_imgs]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Mask out the edges\u001b[39;00m\n\u001b[1;32m    121\u001b[0m plane_imgs \u001b[38;5;241m=\u001b[39m [img \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircle_mask \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m plane_imgs]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skimage/transform/_warps.py:187\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m NumpyVersion(scipy\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.6.0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# The grid_mode kwarg was introduced in SciPy 1.6.0\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     zoom_factors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m factors]\n\u001b[0;32m--> 187\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndi_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# TODO: Remove the fallback code below once SciPy >= 1.6.0 is required.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# 2-dimensional interpolation\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(output_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    194\u001b[0m                                 output_shape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m input_shape[\u001b[38;5;241m2\u001b[39m]):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py:819\u001b[0m, in \u001b[0;36mzoom\u001b[0;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[1;32m    815\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdivide(zoom_nominator, zoom_div,\n\u001b[1;32m    816\u001b[0m                     out\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m    817\u001b[0m                     where\u001b[38;5;241m=\u001b[39mzoom_div \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    818\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mascontiguousarray(zoom)\n\u001b[0;32m--> 819\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algorithms = [simple_nms, crowd_nms] # spicy_nms, global_nms\n",
    "conf_thresholds = [0.6, 0.7, 0.8, 0.9]\n",
    "iou_thresholds = [0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    best_params = None\n",
    "    best_f1 = 0\n",
    "    for c in conf_thresholds:\n",
    "        for i in iou_thresholds:\n",
    "            _, _, f1, _, _, _ = eval_seg(0, iou_threshold=i, conf_threshold=c, nms=algorithm)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = (c, i)\n",
    "    print(f'Best params for {algorithm} are {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 0\n",
      "N = 62\n",
      "Evaluating fold 1\n",
      "N = 62\n",
      "Evaluating fold 2\n",
      "N = 62\n",
      "Evaluating fold 3\n",
      "N = 62\n",
      "Evaluating fold 4\n",
      "N = 62\n",
      "Precision 0.8816839923230733 (0.017096472518584607); Recall 0.8888274243567178 (0.011482971568964842); F1 0.8852077350234266 (0.013556726217415651); Mean Dice 0.9444936133946277 (0.0011286591456861924)\n",
      "Evaluating fold 0\n",
      "N = 62\n",
      "Evaluating fold 1\n",
      "N = 62\n",
      "Evaluating fold 2\n",
      "N = 62\n",
      "Evaluating fold 3\n",
      "N = 62\n",
      "Evaluating fold 4\n",
      "N = 62\n",
      "Precision 0.925548247645515 (0.01026635117917693); Recall 0.812402265407043 (0.014121644760438588); F1 0.8652811412711866 (0.012404216408863735); Mean Dice 0.9437340234908944 (0.0010560684080046247)\n",
      "Evaluating fold 0\n",
      "N = 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5741/2779399981.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  box_keep = np.array(box_keep).tolist()\n",
      "/tmp/ipykernel_5741/2779399981.py:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  box_keep = np.array(box_keep).tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n",
      "N = 62\n",
      "Evaluating fold 2\n",
      "N = 62\n",
      "Evaluating fold 3\n",
      "N = 62\n",
      "Evaluating fold 4\n",
      "N = 62\n",
      "Precision 0.8670909937549409 (0.023328274347099227); Recall 0.8445993031358885 (0.00566135080462436); F1 0.8554628936846559 (0.00852486722857628); Mean Dice 0.9432191722881766 (0.0013864537431772781)\n"
     ]
    }
   ],
   "source": [
    "eval_with_folds(\n",
    "    conf_threshold=0.8,\n",
    "    iou_threshold=0.6,\n",
    "    nms=spicy_nms\n",
    ")\n",
    "\n",
    "eval_with_folds(\n",
    "    conf_threshold=0.8,\n",
    "    iou_threshold=0.6,\n",
    "    nms=global_nms\n",
    ")\n",
    "\n",
    "eval_with_folds(\n",
    "    conf_threshold=0.6,\n",
    "    iou_threshold=0.6,\n",
    "    nms=crowd_nms\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
